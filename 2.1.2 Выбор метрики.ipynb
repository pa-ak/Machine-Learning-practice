{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from numpy import linspace\n",
    "from sklearn.neighbors.classification import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class KNeighborsRegressor in module sklearn.neighbors.regression:\n",
      "\n",
      "class KNeighborsRegressor(sklearn.neighbors.base.NeighborsBase, sklearn.neighbors.base.KNeighborsMixin, sklearn.neighbors.base.SupervisedFloatMixin, sklearn.base.RegressorMixin)\n",
      " |  KNeighborsRegressor(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None, **kwargs)\n",
      " |  \n",
      " |  Regression based on k-nearest neighbors.\n",
      " |  \n",
      " |  The target is predicted by local interpolation of the targets\n",
      " |  associated of the nearest neighbors in the training set.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <regression>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_neighbors : int, optional (default = 5)\n",
      " |      Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
      " |  \n",
      " |  weights : str or callable\n",
      " |      weight function used in prediction.  Possible values:\n",
      " |  \n",
      " |      - 'uniform' : uniform weights.  All points in each neighborhood\n",
      " |        are weighted equally.\n",
      " |      - 'distance' : weight points by the inverse of their distance.\n",
      " |        in this case, closer neighbors of a query point will have a\n",
      " |        greater influence than neighbors which are further away.\n",
      " |      - [callable] : a user-defined function which accepts an\n",
      " |        array of distances, and returns an array of the same shape\n",
      " |        containing the weights.\n",
      " |  \n",
      " |      Uniform weights are used by default.\n",
      " |  \n",
      " |  algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, optional\n",
      " |      Algorithm used to compute the nearest neighbors:\n",
      " |  \n",
      " |      - 'ball_tree' will use :class:`BallTree`\n",
      " |      - 'kd_tree' will use :class:`KDTree`\n",
      " |      - 'brute' will use a brute-force search.\n",
      " |      - 'auto' will attempt to decide the most appropriate algorithm\n",
      " |        based on the values passed to :meth:`fit` method.\n",
      " |  \n",
      " |      Note: fitting on sparse input will override the setting of\n",
      " |      this parameter, using brute force.\n",
      " |  \n",
      " |  leaf_size : int, optional (default = 30)\n",
      " |      Leaf size passed to BallTree or KDTree.  This can affect the\n",
      " |      speed of the construction and query, as well as the memory\n",
      " |      required to store the tree.  The optimal value depends on the\n",
      " |      nature of the problem.\n",
      " |  \n",
      " |  p : integer, optional (default = 2)\n",
      " |      Power parameter for the Minkowski metric. When p = 1, this is\n",
      " |      equivalent to using manhattan_distance (l1), and euclidean_distance\n",
      " |      (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
      " |  \n",
      " |  metric : string or callable, default 'minkowski'\n",
      " |      the distance metric to use for the tree.  The default metric is\n",
      " |      minkowski, and with p=2 is equivalent to the standard Euclidean\n",
      " |      metric. See the documentation of the DistanceMetric class for a\n",
      " |      list of available metrics.\n",
      " |  \n",
      " |  metric_params : dict, optional (default = None)\n",
      " |      Additional keyword arguments for the metric function.\n",
      " |  \n",
      " |  n_jobs : int or None, optional (default=None)\n",
      " |      The number of parallel jobs to run for neighbors search.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |      Doesn't affect :meth:`fit` method.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> X = [[0], [1], [2], [3]]\n",
      " |  >>> y = [0, 0, 1, 1]\n",
      " |  >>> from sklearn.neighbors import KNeighborsRegressor\n",
      " |  >>> neigh = KNeighborsRegressor(n_neighbors=2)\n",
      " |  >>> neigh.fit(X, y) # doctest: +ELLIPSIS\n",
      " |  KNeighborsRegressor(...)\n",
      " |  >>> print(neigh.predict([[1.5]]))\n",
      " |  [0.5]\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  NearestNeighbors\n",
      " |  RadiusNeighborsRegressor\n",
      " |  KNeighborsClassifier\n",
      " |  RadiusNeighborsClassifier\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  See :ref:`Nearest Neighbors <neighbors>` in the online documentation\n",
      " |  for a discussion of the choice of ``algorithm`` and ``leaf_size``.\n",
      " |  \n",
      " |  .. warning::\n",
      " |  \n",
      " |     Regarding the Nearest Neighbors algorithms, if it is found that two\n",
      " |     neighbors, neighbor `k+1` and `k`, have identical distances but\n",
      " |     different labels, the results will depend on the ordering of the\n",
      " |     training data.\n",
      " |  \n",
      " |  https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      KNeighborsRegressor\n",
      " |      sklearn.neighbors.base.NeighborsBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.neighbors.base.KNeighborsMixin\n",
      " |      sklearn.neighbors.base.SupervisedFloatMixin\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict the target for the provided data\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_query, n_features),                 or (n_query, n_indexed) if metric == 'precomputed'\n",
      " |          Test samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array of int, shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          Target values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.neighbors.base.KNeighborsMixin:\n",
      " |  \n",
      " |  kneighbors(self, X=None, n_neighbors=None, return_distance=True)\n",
      " |      Finds the K-neighbors of a point.\n",
      " |      Returns indices of and distances to the neighbors of each point.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_query, n_features),                 or (n_query, n_indexed) if metric == 'precomputed'\n",
      " |          The query point or points.\n",
      " |          If not provided, neighbors of each indexed point are returned.\n",
      " |          In this case, the query point is not considered its own neighbor.\n",
      " |      \n",
      " |      n_neighbors : int\n",
      " |          Number of neighbors to get (default is the value\n",
      " |          passed to the constructor).\n",
      " |      \n",
      " |      return_distance : boolean, optional. Defaults to True.\n",
      " |          If False, distances will not be returned\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dist : array\n",
      " |          Array representing the lengths to points, only present if\n",
      " |          return_distance=True\n",
      " |      \n",
      " |      ind : array\n",
      " |          Indices of the nearest points in the population matrix.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      In the following example, we construct a NeighborsClassifier\n",
      " |      class from an array representing our data set and ask who's\n",
      " |      the closest point to [1,1,1]\n",
      " |      \n",
      " |      >>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]\n",
      " |      >>> from sklearn.neighbors import NearestNeighbors\n",
      " |      >>> neigh = NearestNeighbors(n_neighbors=1)\n",
      " |      >>> neigh.fit(samples) # doctest: +ELLIPSIS\n",
      " |      NearestNeighbors(algorithm='auto', leaf_size=30, ...)\n",
      " |      >>> print(neigh.kneighbors([[1., 1., 1.]])) # doctest: +ELLIPSIS\n",
      " |      (array([[0.5]]), array([[2]]))\n",
      " |      \n",
      " |      As you can see, it returns [[0.5]], and [[2]], which means that the\n",
      " |      element is at distance 0.5 and is the third element of samples\n",
      " |      (indexes start at 0). You can also query for multiple points:\n",
      " |      \n",
      " |      >>> X = [[0., 1., 0.], [1., 0., 1.]]\n",
      " |      >>> neigh.kneighbors(X, return_distance=False) # doctest: +ELLIPSIS\n",
      " |      array([[1],\n",
      " |             [2]]...)\n",
      " |  \n",
      " |  kneighbors_graph(self, X=None, n_neighbors=None, mode='connectivity')\n",
      " |      Computes the (weighted) graph of k-Neighbors for points in X\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_query, n_features),                 or (n_query, n_indexed) if metric == 'precomputed'\n",
      " |          The query point or points.\n",
      " |          If not provided, neighbors of each indexed point are returned.\n",
      " |          In this case, the query point is not considered its own neighbor.\n",
      " |      \n",
      " |      n_neighbors : int\n",
      " |          Number of neighbors for each sample.\n",
      " |          (default is value passed to the constructor).\n",
      " |      \n",
      " |      mode : {'connectivity', 'distance'}, optional\n",
      " |          Type of returned matrix: 'connectivity' will return the\n",
      " |          connectivity matrix with ones and zeros, in 'distance' the\n",
      " |          edges are Euclidean distance between points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A : sparse matrix in CSR format, shape = [n_samples, n_samples_fit]\n",
      " |          n_samples_fit is the number of samples in the fitted data\n",
      " |          A[i, j] is assigned the weight of edge that connects i to j.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> X = [[0], [3], [1]]\n",
      " |      >>> from sklearn.neighbors import NearestNeighbors\n",
      " |      >>> neigh = NearestNeighbors(n_neighbors=2)\n",
      " |      >>> neigh.fit(X) # doctest: +ELLIPSIS\n",
      " |      NearestNeighbors(algorithm='auto', leaf_size=30, ...)\n",
      " |      >>> A = neigh.kneighbors_graph(X)\n",
      " |      >>> A.toarray()\n",
      " |      array([[1., 0., 1.],\n",
      " |             [0., 1., 1.],\n",
      " |             [1., 0., 1.]])\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      NearestNeighbors.radius_neighbors_graph\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.neighbors.base.SupervisedFloatMixin:\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the model using X as training data and y as target values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix, BallTree, KDTree}\n",
      " |          Training data. If array or matrix, shape [n_samples, n_features],\n",
      " |          or [n_samples, n_samples] if metric='precomputed'.\n",
      " |      \n",
      " |      y : {array-like, sparse matrix}\n",
      " |          Target values, array of float values, shape = [n_samples]\n",
      " |           or [n_samples, n_outputs]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the coefficient of determination R^2 of the prediction.\n",
      " |      \n",
      " |      The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      " |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      " |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always\n",
      " |      predicts the expected value of y, disregarding the input features,\n",
      " |      would get a R^2 score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a\n",
      " |          precomputed kernel matrix instead, shape = (n_samples,\n",
      " |          n_samples_fitted], where n_samples_fitted is the number of\n",
      " |          samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True values for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          R^2 of self.predict(X) wrt. y.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The R2 score used when calling ``score`` on a regressor will use\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with `metrics.r2_score`. This will influence the ``score`` method of\n",
      " |      all the multioutput regressors (except for\n",
      " |      `multioutput.MultiOutputRegressor`). To specify the default value\n",
      " |      manually and avoid the warning, please either call `metrics.r2_score`\n",
      " |      directly or make a custom scorer with `metrics.make_scorer` (the\n",
      " |      built-in scorer ``'r2'`` uses ``multioutput='uniform_average'``).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(KNeighborsRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasample = sklearn.datasets.load_boston()\n",
    "y = datasample ['target']\n",
    "x = datasample ['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = scale(x, axis = 0, with_mean=True, with_std=True, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [  1   3   4   5   6   7   8  10  12  13  14  15  16  17  19  20  21  23\n",
      "  24  25  26  27  28  29  31  32  34  35  36  37  38  40  41  42  43  44\n",
      "  45  47  48  49  50  51  52  53  54  56  57  58  59  60  61  62  64  65\n",
      "  66  67  71  74  80  81  83  85  87  88  89  91  92  94  95  96  97  98\n",
      "  99 100 102 103 105 106 107 108 109 110 111 112 113 114 115 116 117 118\n",
      " 119 120 121 122 123 125 126 127 128 129 130 133 134 135 136 138 139 141\n",
      " 142 143 144 145 146 147 148 149 150 151 152 154 155 156 157 158 159 160\n",
      " 161 162 163 164 165 166 167 168 169 170 171 174 175 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 191 192 193 194 196 197 198 199 200\n",
      " 201 202 205 206 207 211 212 213 214 215 216 217 219 220 221 222 223 224\n",
      " 225 226 227 228 230 231 232 233 235 236 237 238 239 240 241 242 243 244\n",
      " 246 247 248 249 250 251 252 253 254 256 257 258 259 260 261 262 263 264\n",
      " 265 266 267 269 270 272 273 275 276 277 279 280 282 283 284 285 286 287\n",
      " 288 289 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306\n",
      " 308 309 310 311 313 314 315 317 318 319 321 322 325 326 327 328 329 330\n",
      " 331 332 333 334 335 337 338 339 340 341 342 343 344 345 347 348 349 350\n",
      " 352 353 354 356 357 358 359 360 361 363 364 366 367 368 369 370 372 373\n",
      " 374 376 377 378 379 380 382 383 384 385 386 387 389 391 393 394 396 397\n",
      " 399 400 401 402 403 404 405 406 407 409 410 413 415 416 418 419 420 422\n",
      " 423 424 425 426 427 428 429 430 431 432 433 434 435 437 438 439 440 441\n",
      " 443 445 446 447 449 450 451 453 455 457 458 459 461 462 463 464 465 466\n",
      " 468 469 472 475 476 477 478 479 480 482 483 484 486 487 488 490 492 493\n",
      " 494 495 498 499 502 503 504 505] TEST: [  0   2   9  11  18  22  30  33  39  46  55  63  68  69  70  72  73  75\n",
      "  76  77  78  79  82  84  86  90  93 101 104 124 131 132 137 140 153 172\n",
      " 173 176 195 203 204 208 209 210 218 229 234 245 255 268 271 274 278 281\n",
      " 290 307 312 316 320 323 324 336 346 351 355 362 365 371 375 381 388 390\n",
      " 392 395 398 408 411 412 414 417 421 436 442 444 448 452 454 456 460 467\n",
      " 470 471 473 474 481 485 489 491 496 497 500 501]\n",
      "TRAIN: [  0   1   2   4   6   8   9  10  11  12  13  14  18  20  21  22  27  28\n",
      "  30  32  33  34  35  36  38  39  40  41  43  44  46  47  48  49  50  51\n",
      "  52  53  54  55  58  59  61  62  63  64  65  68  69  70  71  72  73  74\n",
      "  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  93\n",
      "  95  96  97  98  99 100 101 102 103 104 105 106 107 111 112 115 119 120\n",
      " 121 122 123 124 125 127 128 129 130 131 132 133 134 135 136 137 138 139\n",
      " 140 142 143 146 147 149 150 151 153 156 158 159 160 161 162 163 164 165\n",
      " 166 167 169 170 171 172 173 174 176 177 178 179 183 184 186 187 188 189\n",
      " 190 191 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210\n",
      " 212 213 214 215 216 217 218 219 221 223 224 226 228 229 230 231 232 233\n",
      " 234 235 236 237 239 240 241 242 243 245 246 247 248 251 252 253 254 255\n",
      " 256 257 258 259 260 261 263 264 266 267 268 269 270 271 273 274 275 276\n",
      " 278 279 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296\n",
      " 297 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315\n",
      " 316 317 318 319 320 323 324 326 327 328 330 331 333 336 337 339 340 341\n",
      " 342 343 344 345 346 348 349 350 351 352 353 354 355 357 358 359 362 363\n",
      " 364 365 366 367 368 370 371 372 374 375 376 377 378 379 380 381 382 384\n",
      " 385 386 387 388 389 390 391 392 393 395 396 397 398 399 401 402 403 406\n",
      " 407 408 410 411 412 413 414 415 416 417 419 421 422 424 425 426 427 428\n",
      " 429 430 431 435 436 438 439 440 442 443 444 445 446 448 449 451 452 453\n",
      " 454 455 456 457 458 459 460 461 462 463 464 465 466 467 469 470 471 473\n",
      " 474 475 476 479 480 481 482 483 484 485 486 487 488 489 490 491 494 495\n",
      " 496 497 498 500 501 502 503 504 505] TEST: [  3   5   7  15  16  17  19  23  24  25  26  29  31  37  42  45  56  57\n",
      "  60  66  67  92  94 108 109 110 113 114 116 117 118 126 141 144 145 148\n",
      " 152 154 155 157 168 175 180 181 182 185 192 193 194 211 220 222 225 227\n",
      " 238 244 249 250 262 265 272 277 280 298 321 322 325 329 332 334 335 338\n",
      " 347 356 360 361 369 373 383 394 400 404 405 409 418 420 423 432 433 434\n",
      " 437 441 447 450 468 472 477 478 492 493 499]\n",
      "TRAIN: [  0   1   2   3   4   5   7   8   9  11  12  13  14  15  16  17  18  19\n",
      "  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  37  39\n",
      "  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57\n",
      "  58  60  61  62  63  64  65  66  67  68  69  70  71  72  73  75  76  77\n",
      "  78  79  80  82  84  85  86  87  88  90  91  92  93  94  95  98  99 100\n",
      " 101 102 104 105 106 107 108 109 110 113 114 115 116 117 118 120 121 124\n",
      " 126 127 128 130 131 132 133 134 135 136 137 138 140 141 142 144 145 148\n",
      " 149 151 152 153 154 155 156 157 159 160 161 162 164 166 168 169 170 171\n",
      " 172 173 174 175 176 178 180 181 182 185 186 187 188 189 190 191 192 193\n",
      " 194 195 197 200 201 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 220 221 222 224 225 226 227 229 230 232 233 234 235 236 238\n",
      " 240 241 242 243 244 245 249 250 251 252 254 255 256 257 258 259 260 262\n",
      " 263 264 265 267 268 269 270 271 272 273 274 276 277 278 279 280 281 282\n",
      " 283 285 288 290 292 293 295 298 300 303 306 307 308 309 312 313 314 315\n",
      " 316 319 320 321 322 323 324 325 326 327 328 329 330 332 334 335 336 337\n",
      " 338 339 340 343 344 345 346 347 348 349 350 351 352 355 356 359 360 361\n",
      " 362 363 365 366 367 369 371 372 373 374 375 376 379 381 382 383 385 387\n",
      " 388 389 390 391 392 393 394 395 398 400 401 402 404 405 406 407 408 409\n",
      " 411 412 413 414 415 416 417 418 419 420 421 423 425 426 427 429 430 431\n",
      " 432 433 434 435 436 437 439 440 441 442 443 444 445 446 447 448 449 450\n",
      " 451 452 453 454 456 458 459 460 461 462 463 464 465 466 467 468 469 470\n",
      " 471 472 473 474 477 478 479 481 482 485 486 488 489 491 492 493 494 495\n",
      " 496 497 498 499 500 501 502 504 505] TEST: [  6  10  36  38  59  74  81  83  89  96  97 103 111 112 119 122 123 125\n",
      " 129 139 143 146 147 150 158 163 165 167 177 179 183 184 196 198 199 202\n",
      " 219 223 228 231 237 239 246 247 248 253 261 266 275 284 286 287 289 291\n",
      " 294 296 297 299 301 302 304 305 310 311 317 318 331 333 341 342 353 354\n",
      " 357 358 364 368 370 377 378 380 384 386 396 397 399 403 410 422 424 428\n",
      " 438 455 457 475 476 480 483 484 487 490 503]\n",
      "TRAIN: [  0   1   2   3   5   6   7   9  10  11  13  15  16  17  18  19  20  21\n",
      "  22  23  24  25  26  29  30  31  33  34  36  37  38  39  42  43  45  46\n",
      "  48  49  50  52  53  54  55  56  57  58  59  60  63  66  67  68  69  70\n",
      "  71  72  73  74  75  76  77  78  79  80  81  82  83  84  86  87  88  89\n",
      "  90  91  92  93  94  96  97  99 101 102 103 104 105 106 108 109 110 111\n",
      " 112 113 114 116 117 118 119 121 122 123 124 125 126 129 130 131 132 134\n",
      " 137 139 140 141 143 144 145 146 147 148 149 150 151 152 153 154 155 157\n",
      " 158 160 161 163 165 166 167 168 169 172 173 174 175 176 177 179 180 181\n",
      " 182 183 184 185 187 188 189 190 191 192 193 194 195 196 198 199 201 202\n",
      " 203 204 205 208 209 210 211 214 217 218 219 220 222 223 225 227 228 229\n",
      " 231 234 235 237 238 239 241 243 244 245 246 247 248 249 250 251 252 253\n",
      " 255 257 259 261 262 263 264 265 266 268 269 270 271 272 273 274 275 276\n",
      " 277 278 280 281 284 286 287 289 290 291 293 294 295 296 297 298 299 301\n",
      " 302 303 304 305 306 307 308 309 310 311 312 313 315 316 317 318 319 320\n",
      " 321 322 323 324 325 328 329 330 331 332 333 334 335 336 338 339 341 342\n",
      " 343 344 345 346 347 348 350 351 353 354 355 356 357 358 359 360 361 362\n",
      " 363 364 365 366 368 369 370 371 372 373 375 377 378 380 381 383 384 385\n",
      " 386 387 388 389 390 392 394 395 396 397 398 399 400 401 403 404 405 408\n",
      " 409 410 411 412 413 414 417 418 419 420 421 422 423 424 427 428 430 432\n",
      " 433 434 435 436 437 438 441 442 443 444 445 446 447 448 450 452 454 455\n",
      " 456 457 458 459 460 461 462 463 464 466 467 468 470 471 472 473 474 475\n",
      " 476 477 478 479 480 481 483 484 485 486 487 488 489 490 491 492 493 494\n",
      " 496 497 498 499 500 501 502 503 505] TEST: [  4   8  12  14  27  28  32  35  40  41  44  47  51  61  62  64  65  85\n",
      "  95  98 100 107 115 120 127 128 133 135 136 138 142 156 159 162 164 170\n",
      " 171 178 186 197 200 206 207 212 213 215 216 221 224 226 230 232 233 236\n",
      " 240 242 254 256 258 260 267 279 282 283 285 288 292 300 314 326 327 337\n",
      " 340 349 352 367 374 376 379 382 391 393 402 406 407 415 416 425 426 429\n",
      " 431 439 440 449 451 453 465 469 482 495 504]\n",
      "TRAIN: [  0   2   3   4   5   6   7   8   9  10  11  12  14  15  16  17  18  19\n",
      "  22  23  24  25  26  27  28  29  30  31  32  33  35  36  37  38  39  40\n",
      "  41  42  44  45  46  47  51  55  56  57  59  60  61  62  63  64  65  66\n",
      "  67  68  69  70  72  73  74  75  76  77  78  79  81  82  83  84  85  86\n",
      "  89  90  92  93  94  95  96  97  98 100 101 103 104 107 108 109 110 111\n",
      " 112 113 114 115 116 117 118 119 120 122 123 124 125 126 127 128 129 131\n",
      " 132 133 135 136 137 138 139 140 141 142 143 144 145 146 147 148 150 152\n",
      " 153 154 155 156 157 158 159 162 163 164 165 167 168 170 171 172 173 175\n",
      " 176 177 178 179 180 181 182 183 184 185 186 192 193 194 195 196 197 198\n",
      " 199 200 202 203 204 206 207 208 209 210 211 212 213 215 216 218 219 220\n",
      " 221 222 223 224 225 226 227 228 229 230 231 232 233 234 236 237 238 239\n",
      " 240 242 244 245 246 247 248 249 250 253 254 255 256 258 260 261 262 265\n",
      " 266 267 268 271 272 274 275 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 294 296 297 298 299 300 301 302 304 305 307 310 311\n",
      " 312 314 316 317 318 320 321 322 323 324 325 326 327 329 331 332 333 334\n",
      " 335 336 337 338 340 341 342 346 347 349 351 352 353 354 355 356 357 358\n",
      " 360 361 362 364 365 367 368 369 370 371 373 374 375 376 377 378 379 380\n",
      " 381 382 383 384 386 388 390 391 392 393 394 395 396 397 398 399 400 402\n",
      " 403 404 405 406 407 408 409 410 411 412 414 415 416 417 418 420 421 422\n",
      " 423 424 425 426 428 429 431 432 433 434 436 437 438 439 440 441 442 444\n",
      " 447 448 449 450 451 452 453 454 455 456 457 460 465 467 468 469 470 471\n",
      " 472 473 474 475 476 477 478 480 481 482 483 484 485 487 489 490 491 492\n",
      " 493 495 496 497 499 500 501 503 504] TEST: [  1  13  20  21  34  43  48  49  50  52  53  54  58  71  80  87  88  91\n",
      "  99 102 105 106 121 130 134 149 151 160 161 166 169 174 187 188 189 190\n",
      " 191 201 205 214 217 235 241 243 251 252 257 259 263 264 269 270 273 276\n",
      " 293 295 303 306 308 309 313 315 319 328 330 339 343 344 345 348 350 359\n",
      " 363 366 372 385 387 389 401 413 419 427 430 435 443 445 446 458 459 461\n",
      " 462 463 464 466 479 486 488 494 498 502 505]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "for train_index, test_index in kf.split(x):\n",
    "    print('TRAIN:', train_index, 'TEST:', test_index)\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 1.25, 2.5 , 3.75, 5.  , 6.25, 7.5 , 8.75]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "number = 0\n",
    "max_cvs = 0\n",
    "gruz200 = np.linspace(1,10,num=200)\n",
    "\n",
    "for i in range(1,len(gruz200)-1):\n",
    "    neigh_reg = KNeighborsRegressor(p=i, n_neighbors=5, weights='distance') \n",
    "    cvs = cross_val_score(neigh_reg, x2, y, cv=kf, scoring='neg_mean_squared_error') \n",
    "    if np.mean(cvs) > max_cvs: \n",
    "        max_cvs = np.mean(cvs) \n",
    "        index = i\n",
    "        number = gruz200[i]\n",
    "        \n",
    "\n",
    "print (number,index, max_cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-19.882023  , -13.69648154, -19.07122148, -12.97629251,\n",
       "       -20.10014088])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh_reg = KNeighborsRegressor(p=1.4522613065326633, n_neighbors=5, weights='distance') \n",
    "cvs = cross_val_score(neigh_reg, x2, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "cvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4522613065326633"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gruz200[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0452261306532664 -16.030646734221644\n",
      "1.0904522613065326 -17.333314407343945\n",
      "1.135678391959799 -18.058933618922072\n",
      "1.1809045226130652 -19.16779768325221\n",
      "1.2261306532663316 -19.7560608264777\n",
      "1.271356783919598 -20.12346714345734\n",
      "1.3165829145728645 -20.67084214193783\n",
      "1.3618090452261307 -21.067079980442543\n",
      "1.4070351758793969 -21.017982867148667\n",
      "1.4522613065326633 -21.089703307229723\n",
      "1.4974874371859297 -21.006237632043316\n",
      "1.542713567839196 -20.988072491876384\n",
      "1.5879396984924623 -21.00969796379713\n",
      "1.6331658291457287 -20.85626427201279\n",
      "1.678391959798995 -20.859353797249874\n",
      "1.7236180904522613 -20.8831105192831\n",
      "1.7688442211055277 -20.889425612048807\n",
      "1.814070351758794 -21.115605477059557\n",
      "1.8592964824120604 -21.109485895623617\n",
      "1.9045226130653266 -21.268737502649607\n",
      "1.949748743718593 -21.30384890562258\n",
      "1.9949748743718594 -21.28805479082493\n",
      "2.040201005025126 -21.289785483338353\n",
      "2.085427135678392 -21.290278082901978\n",
      "2.1306532663316586 -21.29316588397132\n",
      "2.1758793969849246 -21.301329602962525\n",
      "2.221105527638191 -21.302334654420793\n",
      "2.2663316582914574 -21.34008471134664\n",
      "2.3115577889447234 -21.33456956582045\n",
      "2.35678391959799 -21.326777936838983\n",
      "2.4020100502512562 -21.275491371695175\n",
      "2.4472361809045227 -21.26905263131444\n",
      "2.492462311557789 -21.28594702911365\n",
      "2.5376884422110555 -21.420632769099733\n",
      "2.582914572864322 -21.450199001187137\n",
      "2.628140703517588 -21.450564371614462\n",
      "2.6733668341708543 -21.48433315803615\n",
      "2.7185929648241207 -21.561402651310694\n",
      "2.7638190954773867 -21.561159095697704\n",
      "2.809045226130653 -21.26956774615959\n",
      "2.8542713567839195 -21.274441322192853\n",
      "2.899497487437186 -21.272527688362203\n",
      "2.9447236180904524 -21.272740145635527\n",
      "2.9899497487437188 -21.272935390467023\n",
      "3.035175879396985 -21.286366880759164\n",
      "3.080402010050251 -21.286532801160114\n",
      "3.1256281407035176 -21.2866862537734\n",
      "3.170854271356784 -21.271960886717885\n",
      "3.2160804020100504 -21.28127507825139\n",
      "3.261306532663317 -21.275235615816918\n",
      "3.306532663316583 -21.27288474428042\n",
      "3.351758793969849 -21.272991381869424\n",
      "3.3969849246231156 -21.27309114242821\n",
      "3.442211055276382 -21.273184625495883\n",
      "3.4874371859296485 -21.254330514762714\n",
      "3.532663316582915 -21.254415217458256\n",
      "3.577889447236181 -21.254030661328386\n",
      "3.6231155778894473 -21.186526477465264\n",
      "3.6683417085427137 -21.18659939103743\n",
      "3.71356783919598 -21.186174792836887\n",
      "3.7587939698492465 -21.18616474000708\n",
      "3.8040201005025125 -21.187650790171315\n",
      "3.849246231155779 -21.187709552060745\n",
      "3.8944723618090453 -21.1877653966378\n",
      "3.9396984924623117 -21.187818527915702\n",
      "3.984924623115578 -21.187869132100282\n",
      "4.030150753768844 -21.187917379397643\n",
      "4.075376884422111 -21.187963425617266\n",
      "4.1206030150753765 -21.1950043326973\n",
      "4.165829145728644 -21.195046393564706\n",
      "4.211055276381909 -21.192267389982575\n",
      "4.256281407035176 -21.19295825333558\n",
      "4.301507537688442 -21.192996312129324\n",
      "4.346733668341709 -21.18920312415307\n",
      "4.391959798994975 -21.18923820625278\n",
      "4.437185929648241 -21.189271924828912\n",
      "4.482412060301508 -21.173036738746603\n",
      "4.527638190954773 -21.173069518937332\n",
      "4.572864321608041 -21.179193067385782\n",
      "4.618090452261306 -21.17754318310624\n",
      "4.6633165829145735 -21.168550890829238\n",
      "4.708542713567839 -21.19046766737906\n",
      "4.7537688442211055 -21.192706694967296\n",
      "4.798994974874372 -21.19052173533192\n",
      "4.844221105527638 -21.191565617679974\n",
      "4.889447236180905 -21.193802209064803\n",
      "4.934673366834171 -21.19382635513279\n",
      "4.9798994974874375 -21.19384974555098\n",
      "5.025125628140704 -21.193872414546078\n",
      "5.07035175879397 -21.19332141551215\n",
      "5.115577889447236 -21.193342736465347\n",
      "5.160804020100502 -21.19336342713946\n",
      "5.206030150753769 -21.191906359071762\n",
      "5.251256281407035 -21.193230331285232\n",
      "5.296482412060302 -21.192525377801736\n",
      "5.341708542713568 -21.196613893140928\n",
      "5.386934673366834 -21.196631723739824\n",
      "5.432160804020101 -21.196649067227543\n",
      "5.477386934673367 -21.194689731193378\n",
      "5.522613065326634 -21.194706156868083\n",
      "5.5678391959799 -21.193959865006576\n",
      "5.613065326633166 -21.198677225366197\n",
      "5.658291457286432 -21.201893514894856\n",
      "5.703517587939698 -21.201689784693507\n",
      "5.748743718592965 -21.201704207644372\n",
      "5.793969849246231 -21.201718273537864\n",
      "5.839195979899498 -21.201731995282337\n",
      "5.884422110552764 -21.201745385185397\n",
      "5.9296482412060305 -21.20175845498834\n",
      "5.974874371859297 -21.2017712158981\n",
      "6.020100502512563 -21.201783678617094\n",
      "6.06532663316583 -21.20179585337103\n",
      "6.110552763819095 -21.210614089367397\n",
      "6.155778894472362 -21.211350189146764\n",
      "6.201005025125628 -21.211361544644628\n",
      "6.2462311557788945 -21.211372649384497\n",
      "6.291457286432161 -21.211383511538465\n",
      "6.336683417085427 -21.211394138936186\n",
      "6.381909547738694 -21.211404539082356\n",
      "6.42713567839196 -21.212058773800692\n",
      "6.472361809045227 -21.217131714927284\n",
      "6.517587939698493 -21.217141479116975\n",
      "6.562814070351759 -21.21715104302947\n",
      "6.608040201005025 -21.2171604127751\n",
      "6.653266331658291 -21.217169594223925\n",
      "6.698492462311558 -21.217178593017184\n",
      "6.743718592964824 -21.217187414578014\n",
      "6.788944723618091 -21.21719606412167\n",
      "6.834170854271357 -21.223285229948594\n",
      "6.8793969849246235 -21.22329354999767\n",
      "6.92462311557789 -21.22330171254289\n",
      "6.969849246231156 -21.22330972205735\n",
      "7.015075376884423 -21.223317582849425\n",
      "7.060301507537688 -21.223990831302217\n",
      "7.105527638190955 -21.223998384565704\n",
      "7.150753768844221 -21.236485025407045\n",
      "7.1959798994974875 -21.236492272596298\n",
      "7.241206030150754 -21.205430084373138\n",
      "7.28643216080402 -21.20350695115519\n",
      "7.331658291457287 -21.20351382310133\n",
      "7.376884422110553 -21.203520576530927\n",
      "7.42211055276382 -21.20352721453826\n",
      "7.467336683417086 -21.20353374011168\n",
      "7.5125628140703515 -21.203540156137933\n",
      "7.557788944723618 -21.203546465406312\n",
      "7.603015075376884 -21.046173231043632\n",
      "7.648241206030151 -21.203558774362797\n",
      "7.693467336683417 -21.203564779176773\n",
      "7.738693467336684 -21.046079654396003\n",
      "7.78391959798995 -21.20357650166488\n",
      "7.8291457286432165 -21.046091190882173\n",
      "7.874371859296483 -21.04609682354252\n",
      "7.919597989949749 -21.046102368687517\n",
      "7.964824120603016 -21.046107828386496\n",
      "8.010050251256281 -21.04611320464354\n",
      "8.055276381909547 -21.046118499399906\n",
      "8.100502512562814 -21.046123714536442\n",
      "8.145728643216081 -21.046128851875814\n",
      "8.190954773869347 -21.046133913184725\n",
      "8.236180904522612 -21.05451902146764\n",
      "8.28140703517588 -21.054620489686435\n",
      "8.326633165829147 -21.054625332974695\n",
      "8.371859296482413 -21.05357128602326\n",
      "8.417085427135678 -21.067307027161057\n",
      "8.462311557788945 -21.05509495478506\n",
      "8.507537688442211 -21.05870856911785\n",
      "8.552763819095478 -21.058713079602065\n",
      "8.597989949748744 -21.047559637243094\n",
      "8.64321608040201 -21.05872191489252\n",
      "8.688442211055277 -21.047568351946097\n",
      "8.733668341708544 -21.049286337398264\n",
      "8.77889447236181 -21.048262499739185\n",
      "8.824120603015075 -21.052722540863805\n",
      "8.869346733668342 -21.051698622324345\n",
      "8.91457286432161 -21.051702698702957\n",
      "8.959798994974875 -21.05170672187085\n",
      "9.00502512562814 -21.051710692876235\n",
      "9.050251256281408 -21.040556722958705\n",
      "9.095477386934673 -21.051718482451143\n",
      "9.14070351758794 -21.05172230297878\n",
      "9.185929648241206 -21.051726075261865\n",
      "9.231155778894472 -21.05172980021568\n",
      "9.27638190954774 -21.051733478731443\n",
      "9.321608040201005 -21.044765397344406\n",
      "9.366834170854272 -21.044137824922196\n",
      "9.412060301507537 -21.044141369242986\n",
      "9.457286432160805 -21.044144870465708\n",
      "9.50251256281407 -21.044148329372668\n",
      "9.547738693467338 -21.044151746726445\n",
      "9.592964824120603 -21.052987636177136\n",
      "9.63819095477387 -21.05299097263639\n",
      "9.683417085427136 -21.069092664096978\n",
      "9.728643216080402 -21.069095859786493\n",
      "9.773869346733669 -21.069099018809503\n",
      "9.819095477386934 -21.0691021417917\n",
      "9.864321608040202 -21.07024970751194\n",
      "9.909547738693467 -21.069108282061503\n",
      "9.954773869346734 -21.070255778668596\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for i in range(1,len(gruz200)-1):\n",
    "    neigh_reg = KNeighborsRegressor(p=i, n_neighbors=5, weights='distance') \n",
    "    cvs = cross_val_score(neigh_reg, x2, y, scoring='neg_mean_squared_error', cv=kf)\n",
    "    print (gruz200[i], np.mean(cvs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
